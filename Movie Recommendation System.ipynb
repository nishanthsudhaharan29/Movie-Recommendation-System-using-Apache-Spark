{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Movie Recommendation Service\n",
    "### Source: https://www.codementor.io/@jadianes/building-a-recommender-with-apache-spark-python-example-app-part1-du1083qbw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a SparkContext configured for local mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File download\n",
    "Small: 100,000 ratings and 2,488 tag applications applied to 8,570 movies by 706 users. Last updated 4/2015.   \n",
    "Full: 21,000,000 ratings and 470,000 tag applications applied to 27,000 movies by 230,000 users. Last updated 4/2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
    "small_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download location(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "datasets_path = os.path.join('/home/jovyan', 'work')\n",
    "complete_dataset_path = os.path.join(datasets_path, 'ml-latest.zip')\n",
    "small_dataset_path = os.path.join(datasets_path, 'ml-latest-small.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "small_f = urllib.request.urlretrieve (small_dataset_url, small_dataset_path)\n",
    "complete_f = urllib.request.urlretrieve (complete_dataset_url, complete_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(small_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)\n",
    "\n",
    "with zipfile.ZipFile(complete_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and parsing datasets\n",
    "Now we are ready to read in each of the files and create an RDD consisting of parsed lines. \n",
    "\n",
    "Each line in the ratings dataset (ratings.csv) is formatted as: \n",
    "+ userId,movieId,rating,timestamp \n",
    "\n",
    "Each line in the movies (movies.csv) dataset is formatted as:\n",
    "+ movieId,title,genres \n",
    "\n",
    "The format of these files is uniform and simple, so we can use Python split() to parse their lines once they are loaded into RDDs. Parsing the movies and ratings files yields two RDDs: \n",
    "+ For each line in the ratings dataset, we create a tuple of (UserID, MovieID, Rating). We drop the timestamp because we do not need it for this recommender.\n",
    "+ For each line in the movies dataset, we create a tuple of (MovieID, Title). We drop the genres because we do not use them for this recommender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ratings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100836 recommendations in the complete dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('1', '1', '4.0'), ('1', '3', '4.0'), ('1', '6', '4.0')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_ratings_file = os.path.join(datasets_path, 'ml-latest-small', 'ratings.csv')\n",
    "small_ratings_raw_data = sc.textFile(small_ratings_file)\n",
    "small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0]\n",
    "# Parse\n",
    "small_ratings_data = small_ratings_raw_data.filter(lambda line: line!=small_ratings_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache()\n",
    "\n",
    "print ('There are {} recommendations in the complete dataset'.format(small_ratings_data.count()))\n",
    "small_ratings_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### movies.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9742 movies in the complete dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('1', 'Toy Story (1995)'),\n",
       " ('2', 'Jumanji (1995)'),\n",
       " ('3', 'Grumpier Old Men (1995)')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the small dataset file\n",
    "small_movies_file = os.path.join(datasets_path, 'ml-latest-small', 'movies.csv')\n",
    "\n",
    "small_movies_raw_data = sc.textFile(small_movies_file)\n",
    "small_movies_raw_data_header = small_movies_raw_data.take(1)[0]\n",
    "# parsing\n",
    "small_movies_data = small_movies_raw_data.filter(lambda line: line!=small_movies_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1])).cache()\n",
    "small_movies_titles = small_movies_data.map(lambda x: (int(x[0]),x[1]))\n",
    "print ('There are {} movies in the complete dataset'.format(small_movies_titles.count()))   \n",
    "small_movies_data.take(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering\n",
    "In Collaborative filtering we make predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption is that if a user A has the same opinion as a user B on an issue, A is more likely to have B's opinion on a different issue x than to have the opinion on x of a user chosen randomly. \n",
    "\n",
    "At first, people rate different items (like videos, images, games). Then, the system makes predictions about a user's rating for an item not rated yet. The new predictions are built upon the existing ratings of other users with similar ratings with the active user. In the image, the system predicts that the user will not like the video.\n",
    "\n",
    "Spark MLlib library for Machine Learning provides a Collaborative Filtering implementation by using Alternating Least Squares. The implementation in MLlib has the following parameters:\n",
    "\n",
    "+ numBlocks is the number of blocks used to parallelize computation (set to -1 to auto-configure).\n",
    "+ rank is the number of latent factors in the model.\n",
    "+ iterations is the number of iterations to run.\n",
    "+ lambda specifies the regularization parameter in ALS.\n",
    "+ implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data.\n",
    "+ alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting ALS parameters using the small dataset\n",
    "In order to determine the best ALS parameters, we will use the small dataset. We need first to split it into train, validation, and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source uses see=0L, which is the previous version of python (2.x)\n",
    "# 0L should be written as 0 from now on\n",
    "training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=0)\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 0.908078105265682\n",
      "For rank 8 the RMSE is 0.916462973348527\n",
      "For rank 12 the RMSE is 0.917665030756129\n",
      "The best model was trained with rank 4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "seed = 5\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print ('For rank {} the RMSE is {}'.format(rank, error))\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print ('The best model was trained with rank {}'.format(best_rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's have a look at how our predictions look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((372, 1084), 3.42419871162954),\n",
       " ((4, 1084), 3.866749726695713),\n",
       " ((402, 1084), 3.4099577968422152)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically we have the UserID, the MovieID, and the Rating, as we have in our ratings dataset. In this case the predictions third element, the rating for that movie and user, is the predicted by our ALS model.\n",
    "\n",
    "#### Then we join these with our validation data (the one that includes ratings) and the result looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 457), (5.0, 4.381060760461434)),\n",
       " ((1, 1025), (5.0, 4.705295366590298)),\n",
       " ((1, 1089), (5.0, 4.979982471805129))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_and_preds.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To that, we apply a squared difference and the we use the mean() action to get the MSE and apply sqrt.\n",
    "\n",
    "#### Finally we test the selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.9113780946334407\n"
     ]
    }
   ],
   "source": [
    "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "predictions = model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print ('For testing data the RMSE is %s' % (error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the complete dataset to build the final model\n",
    "Due to the limitations of virtual machine, we keep using the small dataset instead of complete dataset\n",
    "\n",
    "We need first to split it into training and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build our recommender model, we will use the complete dataset. Therefore, we need to process it the same way we did with the small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27753444 recommendations in the complete dataset\n"
     ]
    }
   ],
   "source": [
    "# Load the complete dataset file\n",
    "complete_ratings_file = os.path.join(datasets_path, 'ml-latest', 'ratings.csv')\n",
    "complete_ratings_raw_data = sc.textFile(complete_ratings_file)\n",
    "complete_ratings_raw_data_header = complete_ratings_raw_data.take(1)[0]\n",
    "\n",
    "# Parse\n",
    "complete_ratings_data = complete_ratings_raw_data.filter(lambda line: line!=complete_ratings_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache()\n",
    "    \n",
    "print (\"There are %s recommendations in the complete dataset\" % (complete_ratings_data.count()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we are ready to train the recommender model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_RDD, test_RDD = complete_ratings_data.randomSplit([7, 3], seed=0)\n",
    "\n",
    "complete_model = ALS.train(training_RDD, best_rank, seed=seed, \n",
    "                           iterations=iterations, lambda_=regularization_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test on our testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.8318265262101795\n"
     ]
    }
   ],
   "source": [
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "predictions = complete_model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print ('For testing data the RMSE is %s' % (error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to make recommendations\n",
    "Although we aim at building an online movie recommender, now that we know how to have our recommender model ready, we can give it a try providing some movie recommendations. This will help us coding the recommending engine later on when building the web service, and will explain how to use the model in any other circumstances.\n",
    "\n",
    "When using collaborative filtering, getting recommendations is not as simple as predicting for the new entries using a previously generated model. Instead, we need to train again the model but including the new user preferences in order to compare them with other users in the dataset. That is, the recommender needs to be trained every time we have new user ratings (although a single model can be used by multiple users of course!). This makes the process expensive, and it is one of the reasons why scalability is a problem (and Spark a solution!). Once we have our model trained, we can reuse it to obtain top recomendations for a given user or an individual rating for a particular movie. These are less costly operations than training the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 58098 movies in the complete dataset\n"
     ]
    }
   ],
   "source": [
    "complete_movies_file = os.path.join(datasets_path, 'ml-latest', 'movies.csv')\n",
    "complete_movies_raw_data = sc.textFile(complete_movies_file)\n",
    "complete_movies_raw_data_header = complete_movies_raw_data.take(1)[0]\n",
    "\n",
    "# Parse\n",
    "complete_movies_data = complete_movies_raw_data.filter(lambda line: line!=complete_movies_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache()\n",
    "\n",
    "complete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]),x[1]))\n",
    "    \n",
    "print (\"There are %s movies in the complete dataset\" % (complete_movies_titles.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing we want to do, is give recommendations of movies with a certain minimum number of ratings. For that, we need to count the number of ratings per movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_and_averages(ID_and_ratings_tuple):\n",
    "    nratings = len(ID_and_ratings_tuple[1])\n",
    "    return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings)\n",
    "\n",
    "movie_ID_with_ratings_RDD = (complete_ratings_data.map(lambda x: (x[1], x[2])).groupByKey())\n",
    "movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages)\n",
    "movie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new user ratings\n",
    "Now we need to rate some movies for the new user. We will put them in a new RDD and we will use the user ID 0, that is not assigned in the MovieLens dataset. Check the dataset movies file for ID to Tittle assignment (so you know what movies are you actually rating)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings: [(0, 7477, 5), (0, 5064, 4), (0, 5080, 1), (0, 5083, 4), (0, 379, 2), (0, 5096, 3), (0, 148238, 2), (0, 148709, 4), (0, 3483, 5), (0, 3513, 3)]\n"
     ]
    }
   ],
   "source": [
    "new_user_ID = 0\n",
    "\n",
    "# The format of each line is (userID, movieID, rating)\n",
    "\n",
    "\n",
    "# My Ratings\n",
    "\n",
    "# new_user_ratings = [\n",
    "#      (0,7477,1), # Eye See You (D-Tox) (2002)\n",
    "#      (0,5064,1), # The Count of Monte Cristo (2002)\n",
    "#      (0,5080,3), # Slackers (2002)\n",
    "#      (0,5083,2), # Rare Birds (2001)\n",
    "#      (0,379,1), # Timecop (1994)\n",
    "#      (0,5096,3), # Baby's Day Out (1994)\n",
    "#      (0,148238,2), # A Very Murray Christmas (2015)\n",
    "#      (0,148709,3), # Mojave (2015)\n",
    "#      (0,3483,3), # Road to El Dorado, The (2000)\n",
    "#      (0,3513,4) # Rules of Engagement (2000)\n",
    "#    ]\n",
    "\n",
    "# My Friend's Ratings\n",
    "\n",
    "new_user_ratings = [\n",
    "     (0,7477,5), # Eye See You (D-Tox) (2002)\n",
    "     (0,5064,4), # The Count of Monte Cristo (2002)\n",
    "     (0,5080,1), # Slackers (2002)\n",
    "     (0,5083,4), # Rare Birds (2001)\n",
    "     (0,379,2), # Timecop (1994)\n",
    "     (0,5096,3), # Baby's Day Out (1994)\n",
    "     (0,148238,2), # A Very Murray Christmas (2015)\n",
    "     (0,148709,4), # Mojave (2015)\n",
    "     (0,3483,5), # Road to El Dorado, The (2000)\n",
    "     (0,3513,3) # Rules of Engagement (2000)\n",
    "\n",
    "   ]\n",
    "\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
    "print ('New user ratings: {}'.format(new_user_ratings_RDD.take(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add them to the data we will use to train our recommender model. We use Spark's union() transformation for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we train the ALS model using all the parameters we selected before (when using the small dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model trained in 150.85 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, \n",
    "                              iterations=iterations, lambda_=regularization_parameter)\n",
    "tt = time() - t0\n",
    "\n",
    "print (\"New model trained in %s seconds\" % round(tt,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting top recommendations\n",
    "Let's now get some recommendations! For that we will get an RDD with all the movies the new user hasn't rated yet. We will them together with the model to predict ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n",
    "# keep just those not on the ID list (thanks Lei Li for spotting the error!)\n",
    "new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
    "\n",
    "# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
    "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our recommendations ready. Now we can print out the 25 movies with the highest predicted ratings. And join them with the movies RDD to get the titles, and ratings count in order to get movies with a minimum number of counts. First we will do the join and see what does the result looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6216,\n",
       "  ((4.556600405817434, 'Nowhere in Africa (Nirgendwo in Afrika) (2001)'),\n",
       "   717)),\n",
       " (124320, ((4.732577932571873, 'Once a Thief (1965)'), 1)),\n",
       " (83916, ((1.8965047144638127, 'Blues in the Night (1941)'), 9))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
    "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
    "new_user_recommendations_rating_title_and_count_RDD.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need to flat this down a bit in order to have (Title, Rating, Ratings Count)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, get the highest rated recommendations for the new user, filtering out movies with less than 25 ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 15 recommended movies (with more than 100 reviews):\n",
      "('Anne of Green Gables: The Sequel (a.k.a. Anne of Avonlea) (1987)', 5.335650927546585, 342)\n",
      "('North & South (2004)', 5.310135356892424, 389)\n",
      "('Anne of Green Gables (1985)', 5.25009056091133, 706)\n",
      "('Pride and Prejudice (1995)', 5.199110857850529, 2919)\n",
      "('\"Sound of Music', 5.022057410686416, 17154)\n",
      "('\"Civil War', 4.979776328784126, 431)\n",
      "('Wild China (2008)', 4.960534393596472, 105)\n",
      "('Emma (2009)', 4.955623211434325, 385)\n",
      "(\"Schindler's List (1993)\", 4.953946402634649, 71516)\n",
      "('Sense and Sensibility (1995)', 4.949351577356179, 24552)\n",
      "('Jane Eyre (2006)', 4.930973659948204, 327)\n",
      "(\"It's a Wonderful Life (1946)\", 4.929851651350551, 17770)\n",
      "('My Fair Lady (1964)', 4.90786584177767, 12089)\n",
      "('Persuasion (2007)', 4.90078438594999, 349)\n",
      "('Hidden Figures (2016)', 4.896389604611755, 2647)\n"
     ]
    }
   ],
   "source": [
    "# top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=25).takeOrdered(15, key=lambda x: -x[1])\n",
    "\n",
    "# print ('TOP 15 recommended movies (with more than 25 reviews):\\n%s' %\n",
    "#         '\\n'.join(map(str, top_movies)))\n",
    "\n",
    "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=100).takeOrdered(15, key=lambda x: -x[1])\n",
    "\n",
    "print ('TOP 15 recommended movies (with more than 100 reviews):\\n%s' %\n",
    "        '\\n'.join(map(str, top_movies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting individual ratings\n",
    "Another useful usecase is getting the predicted rating for a particular movie for a given user. The process is similar to the previous retreival of top recommendations but, instead of using predcitAll with every single movie the user hasn't rated yet, we will just pass the method a single entry with the movie we want to predict the rating for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=0, product=116688, rating=1.423140448961824)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_movie = sc.parallelize([(0, 500)]) # Quiz Show (1994)\n",
    "individual_movie_rating_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n",
    "individual_movie_rating_RDD.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre and other fields\n",
    "We haven't used the genre and timestamp fields in order to simplify the transformations and the whole tutorial. Incorporating them doesn't represent any problem. A good use could be filtering recommendations by any of them (e.g. recommendations by genre, or recent recommendations) like we have done with the minimum number of ratings.\n",
    "\n",
    "## Conclusion\n",
    "Spark's MLlib library provides scalable data analytics through a rich set of methods. Its Alternating Least Squares implementation for Collaborative Filtering is one that fits perfectly in a recommendation engine. Due to its very nature, collaborative filtering is a costly procedure since requires updating its model when new user preferences arrive. Therefore, having a distributed computation engine such as Spark to perform model computation is a must in any real-world recommendation engine like the one we have built here.\n",
    "\n",
    "Through this tutorial we have described how to build a model using Spark, how to perform some parameter selection using a reduced dataset, and how to update the model every time that new user preferences come in. Additionally, we have explained how the recommender is used in different situations and how its results are joined with product metadata (e.g. movie titles) in order to present its results in a proper way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply two new users (i.e., yourself, and a friend/family member) with each personâ€™s ratings of 10 movies (use the section, Adding new user ratings). You need to run one user at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My Ratings\n",
    "new_user_ratings = [    \n",
    "     (0,7477,1), # Eye See You (D-Tox) (2002)    \n",
    "     (0,5064,1), # The Count of Monte Cristo (2002)    \n",
    "     (0,5080,3), # Slackers (2002)    \n",
    "     (0,5083,2), # Rare Birds (2001)    \n",
    "     (0,379,1), # Timecop (1994)    \n",
    "     (0,5096,3), # Baby's Day Out (1994)    \n",
    "     (0,148238,2), # A Very Murray Christmas (2015)    \n",
    "     (0,148709,3), # Mojave (2015)    \n",
    "     (0,3483,3), # Road to El Dorado, The (2000)    \n",
    "     (0,3513,4) # Rules of Engagement (2000)    \n",
    "   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My Friend's Ratings\n",
    "new_user_ratings = [    \n",
    "     (0,7477,5), # Eye See You (D-Tox) (2002)    \n",
    "     (0,5064,4), # The Count of Monte Cristo (2002)     \n",
    "     (0,5080,1), # Slackers (2002)     \n",
    "     (0,5083,4), # Rare Birds (2001)      \n",
    "     (0,379,2), # Timecop (1994)      \n",
    "     (0,5096,3), # Baby's Day Out (1994)            \n",
    "     (0,148238,2), # A Very Murray Christmas (2015)          \n",
    "     (0,148709,4), # Mojave (2015)       \n",
    "     (0,3483,5), # Road to El Dorado, The (2000)     \n",
    "     (0,3513,3) # Rules of Engagement (2000)     \n",
    "\n",
    "   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate top 15 recommended movies for each user\n",
    "Scenario 1 - FULL dataset, filtering out movies with less than 25 ratings (meaning 25 or more ratings)      \n",
    "Scenario 2 - FULL dataset, filtering out movies with less than 100 ratings (meaning 100 or more ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User 1 - Scenario 1\n",
    "\n",
    "TOP 15 recommended movies (with more than 25 reviews):    \n",
    "('Loose Change 9/11: An American Coup (2009)', 2.9481489449099487, 46)    \n",
    "('Jimmy Carr: Comedian (2007)', 2.929652793856018, 30)     \n",
    "('Jim Jefferies: Contraband (2008)', 2.8668544147203816, 31)     \n",
    "('Tom Segura: Completely Normal (2014)', 2.8598621319599564, 33)       \n",
    "('Cosmos: A Spacetime Odissey', 2.858895879752192, 37)           \n",
    "('Jimmy Carr: Being Funny (2011)', 2.8566759705250915, 25)            \n",
    "('Firebase (2017)', 2.850174269700494, 29)        \n",
    "('Louis C.K.: One Night Stand (2005)', 2.839191099963582, 38)          \n",
    "('The Lost Room (2006)', 2.8359560302691724, 280)         \n",
    "('Jim Jefferies: Alcoholocaust (2010)', 2.8220375209151563, 53)            \n",
    "('Daniel Tosh: Happy Thoughts (2011)', 2.817290853546212, 27)         \n",
    "('Jimmy Carr: Telling Jokes (2009)', 2.808957177335726, 37)            \n",
    "('Perfectos desconocidos (2017)', 2.8064162374641786, 35)            \n",
    "('DMB (2000)', 2.805681682938827, 29)            \n",
    "('\"Story of Luke', 2.8011097627490527, 31)           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User 1 - Scenario 2\n",
    "\n",
    "TOP 15 recommended movies (with more than 100 reviews):              \n",
    "('The Lost Room (2006)', 2.8359560302691724, 280)                \n",
    "('Black Mirror: White Christmas (2014)', 2.7906121293517714, 1074)               \n",
    "('Sherlock - A Study in Pink (2010)', 2.7589584333082584, 213)              \n",
    "('Band of Brothers (2001)', 2.755669305103818, 984)              \n",
    "('Law Abiding Citizen (2009)', 2.747497605442518, 2570)              \n",
    "('\"Matrix', 2.7456716299129305, 84545)              \n",
    "('Black Mirror', 2.7374457472060243, 180)              \n",
    "('\"Shawshank Redemption', 2.735032725984513, 97999)            \n",
    "('\"Dark Knight', 2.7338810864344367, 44741)             \n",
    "('Saw (2003)', 2.7314120779550466, 674)                   \n",
    "('Limitless (2011)', 2.7199078882138386, 9884)             \n",
    "('\"Boondock Saints', 2.7151981868757353, 11214)              \n",
    "('Avengers: Infinity War - Part I (2018)', 2.7146535995028804, 2668)              \n",
    "('Gladiator (2000)', 2.707570786796058, 48666)             \n",
    "('Inception (2010)', 2.7033616454658347, 41475)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User 2 - Scenario 1\n",
    "\n",
    "TOP 15 recommended movies (with more than 25 reviews):                  \n",
    "('\"Very Potter Sequel', 5.402075474560762, 35)                 \n",
    "('Sense & Sensibility (2008)', 5.3776839046314455, 69)                \n",
    "('Anne of Green Gables: The Sequel (a.k.a. Anne of Avonlea) (1987)', 5.335650927546585, 342)                 \n",
    "('Cranford (2007)', 5.323038303364424, 35)               \n",
    "('North & South (2004)', 5.310135356892424, 389)                \n",
    "('Drishyam (2013)', 5.255280979471657, 37)                 \n",
    "('Anne of Green Gables (1985)', 5.25009056091133, 706)                \n",
    "('Pride and Prejudice (1995)', 5.199110857850529, 2919)                 \n",
    "('Murder on the Orient Express (2010)', 5.182371057817914, 29)                  \n",
    "('I Can Only Imagine (2018)', 5.180623692610432, 30)                    \n",
    "('Winter in Prostokvashino (1984)', 5.1467791284786335, 67)                    \n",
    "('Boys (2014)', 5.141713053618693, 96)                  \n",
    "('Little Dorrit (2008)', 5.132472734383583, 55)                       \n",
    "(\"Won't You Be My Neighbor? (2018)\", 5.0994357608513745, 83)                    \n",
    "('The Case for Christ (2017)', 5.09381497368954, 33)                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User 2 - Scenario 2\n",
    "\n",
    "TOP 15 recommended movies (with more than 100 reviews):                           \n",
    "('Anne of Green Gables: The Sequel (a.k.a. Anne of Avonlea) (1987)', 5.335650927546585, 342)                     \n",
    "('North & South (2004)', 5.310135356892424, 389)                  \n",
    "('Anne of Green Gables (1985)', 5.25009056091133, 706)                         \n",
    "('Pride and Prejudice (1995)', 5.199110857850529, 2919)                       \n",
    "('\"Sound of Music', 5.022057410686416, 17154)                   \n",
    "('\"Civil War', 4.979776328784126, 431)                      \n",
    "('Wild China (2008)', 4.960534393596472, 105)                       \n",
    "('Emma (2009)', 4.955623211434325, 385)                \n",
    "(\"Schindler's List (1993)\", 4.953946402634649, 71516)                    \n",
    "('Sense and Sensibility (1995)', 4.949351577356179, 24552)              \n",
    "('Jane Eyre (2006)', 4.930973659948204, 327)                   \n",
    "(\"It's a Wonderful Life (1946)\", 4.929851651350551, 17770)                     \n",
    "('My Fair Lady (1964)', 4.90786584177767, 12089)               \n",
    "('Persuasion (2007)', 4.90078438594999, 349)                          \n",
    "('Hidden Figures (2016)', 4.896389604611755, 2647)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret the results and provide Insights/Foresights on both scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User 1 - Scenario 1    \n",
    "The top 15 recommended movies for User 1 in Scenario 1, where movies with less than 25 ratings were filtered out, show a diverse range of genres and styles. The recommendations cater to different preferences and include both popular and lesser-known films, ensuring a mix of familiar choices and potential new discoveries for User 1.\n",
    "\n",
    "User 1 - Scenario 2      \n",
    "In Scenario 2, where movies with less than 100 ratings were filtered out, the top 15 recommended movies for User 1 exhibit a higher level of popularity and mainstream appeal. The recommendations lean towards well-known movies, including several acclaimed blockbusters and cult classics, aligning with User 1's broader preferences.\n",
    "\n",
    "User 2 - Scenario 1     \n",
    "The top 15 recommended movies for User 2 in Scenario 1, with movies below 25 ratings filtered out, showcase a distinct preference for specific genres or styles. The recommendations highlight a particular niche, with a focus on independent films, foreign cinema, or niche genres that resonate with User 2's unique tastes.\n",
    "\n",
    "User 2 - Scenario 2     \n",
    "Scenario 2, where movies with less than 100 ratings were filtered out, presents the top 15 recommended movies for User 2. These recommendations reflect a broader range of popular and critically acclaimed films, including both mainstream and niche choices. User 2's preferences demonstrate a mix of popular choices and lesser-known gems from various genres.\n",
    "\n",
    "Overall, the recommendations for both users and across different scenarios provide a balance between personalized suggestions and broader appeal. The filtering criteria influence the recommendations, resulting in a selection that aligns with user preferences while also considering the popularity and availability of the movies. These results demonstrate the effectiveness of the collaborative recommendation engine in providing diverse and tailored movie recommendations for users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
